## SpiderDaguo——自定义过滤规则的精品文章爬取工具

### 项目背景
如今移动互联网时代的信息迭代速度越来越快，可以说这是一个信息爆炸的时代，无论是程序员，产品经理，财务管理还是学生党，每天都会接收到各种各样的信息，这些信息鱼目混杂，泥沙俱下，而且我们往往还需要通过各种渠道和步骤，才能获取到信息，比如我日常刷的APP ，用的频率高了之后觉得切换也比较麻烦，这令我们不胜其烦，不禁感慨，要是能随心所欲收集起各门户的精品文章就爽了~


### 初衷 
SpiderDaguo旨在帮不同身份的人提供更加符合预期的精品文章，剔除庞大信息中的糟粕，取其精华，使我们能保有最多的精力来阅读这些文章，更重要的是它提供可定制的文章筛选功能，你可以选择你喜欢的门户，要求的推送限制，比如至少要1000个赞的文章才收集，甚至推送时间，文章存储结构，匹配要求字段，一键搜索各大主流门户相关字眼的资讯干货，等等，当然这些都有默认的主流选项，你可以只关心设置你想使用的功能。

### 项目结构 
项目主要基于Node.js的爬虫代码，使用superagent模块的请求封装，来发送请求到各大门户网站，返回爬取得网页内容，网页的结构处理使用与Jquery有类似语法的cheerio，使用promise来利用异步爬取网页。

* site目录用于存放不同门户网站的爬虫对象，里面各门户的模板需要根据不同的页面结构，人工开发必要的list，article页爬虫逻辑，已及非必要的翻页，局部过滤函数，是项目时间成本主要投入点
* article目录用来存放产出的article文章对象
* app.js是爬取任务的启动文件，运行node app.js将启动爬取任务
* config.js是爬取过程的配置文件
* spider.js是不同爬虫通用的一些属性和方法
* tools.js存放一些工具函数

